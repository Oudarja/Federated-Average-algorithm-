{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c9b4a3f",
   "metadata": {},
   "source": [
    "# Here C[client fraction]=0.1 and E[local epoch on each client]=5 ,bs[batch size ]=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9968fb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import pickle \n",
    "%matplotlib inline\n",
    "import matplotlib as mpl \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "#tqdm is a package for Python that enables you to instantly \n",
    "#create progress bars and estimate TTC (Time To Completion) for your functions and loops!\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "#from tensorflow.keras.optimizers.legacy import SGD\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91251e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Federated_implementation_utils has been imported \n",
    "#from Federated_implementation_utils import *\n",
    "from Federated_implementation_utils_minmax_cifar import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a02dab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = load('X_train.pkl')\n",
    "X_test=load('X_test.pkl')\n",
    "y_train=pickle.load(open('y_train.pkl','rb'))\n",
    "y_test=pickle.load(open('y_test.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84039ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#see the pickle file\n",
    "with open('X_train.pkl','rb') as pickle_file: \n",
    "    new_data=pickle.load(pickle_file)\n",
    "\n",
    "new_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed630c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388f8a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbe11eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6453c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=y_train.reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e8edf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tolist(), used to convert the data elements of an array into a list. \n",
    "#This function returns the array as an a. ndim- levels deep nested list of Python scalars.\n",
    "labels = list(set(y_train.tolist())) #unique labels\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a77eca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_values = np.max(y_train)+1\n",
    "\n",
    "'''\n",
    "numpy.eye(R, C = None, k = 0, dtype = type <‘float’>) : –The eye tool returns a 2-D array with  1’s as the diagonal\n",
    "and  0’s elsewhere. The diagonal can be main, upper, or lower depending on the optional parameter k. \n",
    "A positive k is for the upper diagonal, a negative k is for the lower, and a  0 k (default) is for the main diagonal.\n",
    "'''\n",
    "#[[1 0]\n",
    "# [0 1]] is created and depending upon the class value 0 or 1 0 th or 1st row is selected and stored in label_list\n",
    "label_list = np.eye(n_values)[y_train]\n",
    "print(label_list)\n",
    "#Label_list is changed 1 0 when this means that 0 index should have high probabilty to be classified and 0 1 when 1 index \n",
    "#should have high probability to be classified .It is done as because MLP classifier picks up the index of highest probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94752ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48d14f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9312bb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db9e9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b87696",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=y_test.reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a338d278",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856a1823",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tolist(), used to convert the data elements of an array into a list. \n",
    "#This function returns the array as an a. ndim- levels deep nested list of Python scalars.\n",
    "labels = list(set(y_test.tolist())) #unique labels\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa7accf",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_values = np.max(y_test)+1\n",
    "\n",
    "'''\n",
    "numpy.eye(R, C = None, k = 0, dtype = type <‘float’>) : –The eye tool returns a 2-D array with  1’s as the diagonal\n",
    "and  0’s elsewhere. The diagonal can be main, upper, or lower depending on the optional parameter k. \n",
    "A positive k is for the upper diagonal, a negative k is for the lower, and a  0 k (default) is for the main diagonal.\n",
    "'''\n",
    "#[[1 0]\n",
    "# [0 1]] is created and depending upon the class value 0 or 1 0 th or 1st row is selected and stored in label_list\n",
    "label_list = np.eye(n_values)[y_test]\n",
    "print(label_list)\n",
    "#Label_list is changed 1 0 when this means that 0 index should have high probabilty to be classified and 0 1 when 1 index \n",
    "#should have high probability to be classified .It is done as because MLP classifier picks up the index of highest probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c9dbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2d5de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bb6991",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create clients\n",
    "#Here initial is for client1,client2,....clientK client name \n",
    "clients = create_clients_NONIID(X_train, y_train, num_clients=100, initial='client') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339a8374",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clients[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e895b2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(clients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0860ee88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#process and batch the training data for each client\n",
    "#Dictionary of clients is created and the key will be client name and the value will be batched data set batch size is 32\n",
    "clients_batched = dict()\n",
    "for (client_name, data) in clients.items():\n",
    "    #Storing batched data on each client dictionary\n",
    "    #batch size is 50\n",
    "    clients_batched[client_name] = batch_data(data,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5c0a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clients_batched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdebbd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#process and batch the test set  \n",
    "test_batched = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d75d36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_batched)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e49e527",
   "metadata": {},
   "source": [
    "### Creating global model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b65a977",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    global_model = tf.keras.models.Sequential()\n",
    "    global_model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(24,24,3)))\n",
    "    global_model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "    global_model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    global_model.add(tf.keras.layers.Flatten())\n",
    "    global_model.add(tf.keras.layers.Dense(180, activation='relu'))\n",
    "    global_model.add(tf.keras.layers.Dense(90, activation='relu'))\n",
    "    global_model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "    global_model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "    return global_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae42750",
   "metadata": {},
   "outputs": [],
   "source": [
    "comms_round = 100\n",
    "E=5\n",
    "global_model1=create_model()\n",
    "global_model1.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1335b5f7",
   "metadata": {},
   "source": [
    "### Enhancing  fedavg through global shared model[GSM Fedavg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936301d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#commence global training loop\n",
    "#participation ratio of clients at each round\n",
    "C=0.1\n",
    "X_com=[]\n",
    "Y_acc_avg_up=[]\n",
    "Y_loss_avg_up=[]\n",
    "Y_acc_avg=[]\n",
    "Y_loss_avg=[]\n",
    "\n",
    "for comm_round in range(comms_round):\n",
    "    \n",
    "    # get the global model's weights - will serve as the initial weights for all local models\n",
    "    #This function returns a list consisting of NumPy arrays. The first array gives the weights of the layer and \n",
    "    #the second array gives the biases.\n",
    "    global_weights1= global_model1.get_weights()\n",
    "    #initial list to collect local model weights after scalling\n",
    "    scaled_local_weight_list1 = list()\n",
    "    #randomize client data - using keys\n",
    "    client_names= list(clients_batched.keys()) #Here client name has been stored in client_names\n",
    "    random.shuffle(client_names)\n",
    "    client_names=client_names[0:int(max(C*len(clients),1))]\n",
    "    \n",
    "    #loop through each client and create new local model\n",
    "    for client in tqdm(client_names , desc = 'Progress Bar'):\n",
    "        #time.sleep(0.5)\n",
    "        local_model1 = global_model1\n",
    "        \n",
    "        #set local model weight to the weight of the global model\n",
    "        #local_model.set_weights(global_weights)\n",
    "        \n",
    "        # get the batched data for the client\n",
    "        client_data = clients_batched[client]\n",
    "        \n",
    "        # get the number of batches in the client's data\n",
    "        num_batches = tf.data.experimental.cardinality(client_data)\n",
    "            \n",
    "        for batch in client_data:\n",
    "            X, y = batch\n",
    "            bs = len(X)\n",
    "            local_model1.fit(X, y, epochs=E, verbose=0, batch_size=bs)\n",
    "            \n",
    "        #scale the model weights and add to list\n",
    "        scaling_factor = weight_scalling_factor(clients_batched, client,client_names)\n",
    "        #Now each attributes weights has been multiplied by scalling factor for each client\n",
    "        scaled_weights1 = scale_model_weights(local_model1.get_weights(), scaling_factor)\n",
    "        #scaled weight list now stored for each client\n",
    "        scaled_local_weight_list1.append(scaled_weights1)\n",
    "        #clear session to free memory after each communication round\n",
    "        K.clear_session()\n",
    "        \n",
    "    #to get the average over all the local model, we simply take the sum of the scaled weights\n",
    "    average_weights1 = sum_scaled_weights(scaled_local_weight_list1)\n",
    "        \n",
    "    #update global model \n",
    "    global_model1.set_weights(average_weights1)\n",
    "\n",
    "    #test global model and print out metrics after each communications round\n",
    "    for(X_test, Y_test) in test_batched:\n",
    "        print('Fedavg:')\n",
    "        global_acc, global_loss = test_model(X_test, Y_test, global_model1,comm_round)\n",
    "        X_com.append(comm_round)\n",
    "        Y_acc_avg_up.append(global_acc)\n",
    "        Y_loss_avg_up.append(global_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8c2ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure()\n",
    "f.set_figwidth(7)\n",
    "f.set_figheight(7)\n",
    "plt.plot(X_com,Y_acc_avg_up,color='orange')\n",
    "plt.title('CIFAR NONIID ACC')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Communication round')\n",
    "plt.legend(['Fedavg\\nB=50\\nE=1\\nC=0.1'],loc='lower right')\n",
    "plt.savefig(\"Comparison acc.jpg\",dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d40421",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure()\n",
    "f.set_figwidth(7)\n",
    "f.set_figheight(7)\n",
    "plt.plot(X_com,Y_loss_avg_up,color='orange')\n",
    "plt.plot(X_com,Y_loss_avg,color='blue')\n",
    "plt.title('CIFAR NONIID LOSS')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Communication round')\n",
    "plt.legend(['Fedavg\\nB=50\\nE=1\\nC=0.1'],loc='upper right')\n",
    "plt.savefig(\"Comparison loss.jpg\",dpi=300)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
