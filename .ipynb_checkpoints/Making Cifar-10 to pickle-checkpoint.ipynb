{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6dc0499",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras import datasets\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0497e8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets,layers,models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0060177c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train,y_train),(X_test,y_test)=datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cc34a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape\n",
    "#So each image has been defined in 32*32 pixel in each pixel there are 3 channel for R,G,B value as red ,green,blue \n",
    "#can be used to define any color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ef7260",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366b2024",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51aeb6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6d2211",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4984c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_X_train = tf.image.resize(X_train, (24, 24))\n",
    "resized_X_test = tf.image.resize(X_test, (24, 24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea8c14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#resized_X_train=tf.image.adjust_contrast(resized_X_train,1)\n",
    "#resized_X_test=tf.image.adjust_contrast(resized_X_test,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82584cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#resized_X_train=tf.image.adjust_brightness(resized_X_train,2.855)\n",
    "#resized_X_test=tf.image.adjust_brightness(resized_X_test,2.855)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76d4395",
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b306a4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dacd46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eda4a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_resized_np = np.array(resized_X_train.numpy(), dtype=np.uint8)\n",
    "test_images_resized_np = np.array(resized_X_test.numpy(), dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71bbdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_resized_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f17518",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_resized_np[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf81e2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the resized image \n",
    "plt.figure(figsize=(6,4))\n",
    "plt.imshow(train_images_resized_np[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c02f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the resized image \n",
    "plt.figure(figsize=(6,4))\n",
    "plt.imshow(test_images_resized_np[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ea6d8d",
   "metadata": {},
   "source": [
    "### The image resizing operation may cause some distortion or loss of information depending on the original image size and the target size. However, if the target size is not too different from the original size, the distortion should be minimal and the image should be still properly visible. In the case of resizing CIFAR-10 images from 32x32x3 to 24x24x3, the distortion should be minimal.\n",
    "### That being said, if you want to avoid any distortion or loss of information, you may want to consider using padding to resize the images instead of directly resizing them. This will add padding around the images to make them fit the target size without changing their aspect ratio. Here is an example code that uses padding to resize CIFAR-10 images to 24x24x3:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c1063c",
   "metadata": {},
   "source": [
    "#### Different kind of algorithm for interpolation methos\n",
    "#### AREA\t'area'\n",
    "#### BICUBIC\t'bicubic'\n",
    "#### BILINEAR\t'bilinear'\n",
    "#### GAUSSIAN\t'gaussian'\n",
    "#### LANCZOS3\t'lanczos3'\n",
    "#### LANCZOS5\t'lanczos5'\n",
    "#### MITCHELLCUBIC\t'mitchellcubic'\n",
    "#### NEAREST_NEIGHBOR\t'nearest'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebd6dda",
   "metadata": {},
   "source": [
    "# Here various kinds of interpolation can be applied but in this case it seems that the default interpolation is good  so that has been  taken "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988df59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.cifar10.load_data()\n",
    "# add padding to resize images to 24x24x3\n",
    "\n",
    "#Here the target size is 36 for width and height and the X_train width is 32 so target height and width >=current height+ offset\n",
    "#here offset is 4\n",
    "train_images_resized = tf.image.pad_to_bounding_box(X_train,4,4,36,36)\n",
    "test_images_resized = tf.image.pad_to_bounding_box(X_test, 4,4,36,36)\n",
    "'''\n",
    "tf.image.resize(images,size,method=ResizeMethod.BILINEAR,preserve_aspect_ratio=False,antialias=False,name=None)\n",
    "'''\n",
    "'''\n",
    "tf.image.resize() uses the bilinear interpolation algorithm, which computes each new pixel value as a weighted average\n",
    "of the four nearest original pixels. Other interpolation algorithms available in TensorFlow include\n",
    "nearest neighbor, bicubic, and Lanczos.\n",
    "'''\n",
    "train_images_resized1 = tf.image.resize(train_images_resized, (24, 24),antialias=True,method=tf.image.ResizeMethod.MITCHELLCUBIC,\n",
    "                                            preserve_aspect_ratio=True)\n",
    "test_images_resized1 = tf.image.resize(test_images_resized, (24, 24),antialias=True,method=tf.image.ResizeMethod.MITCHELLCUBIC,\n",
    "                                       preserve_aspect_ratio=True)\n",
    "#27-4+1=24 so 24*24 image is found\n",
    "train_images_resized1 = train_images_resized1[:, 4:28, 4:28, :]\n",
    "test_images_resized1 = test_images_resized1[:, 4:28, 4:28, :]\n",
    "\n",
    "# convert resized images to NumPy arrays with dtype uint8\n",
    "train_images_resized_np1 = np.array(train_images_resized1.numpy(), dtype=np.uint8)\n",
    "test_images_resized_np1 = np.array(test_images_resized1.numpy(), dtype=np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da1b2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "plt.imshow(train_images_resized_np1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39192a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the old image\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.imshow(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92832e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the old image\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.imshow(X_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab05b87",
   "metadata": {},
   "source": [
    "## Here pickle file is dumped "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a885fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('X_train.pkl','wb') as pickle_file: \n",
    "    pickle.dump(train_images_resized_np,pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c4cfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('X_test.pkl','wb') as pickle_file: \n",
    "    pickle.dump(test_images_resized_np,pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c84a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('y_train.pkl','wb') as pickle_file: \n",
    "    pickle.dump(y_train,pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5587e97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('y_test.pkl','wb') as pickle_file: \n",
    "    pickle.dump(y_test,pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc60665",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = tf.keras.models.Sequential()\n",
    "global_model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "global_model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "global_model.add(tf.keras.layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "global_model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "global_model.add(tf.keras.layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "global_model.add(tf.keras.layers.Flatten())\n",
    "global_model.add(tf.keras.layers.Dense(512, activation='relu'))\n",
    "global_model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "global_model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "global_model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "global_model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "global_model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "# Print the model summary\n",
    "global_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e34026",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = models.Sequential()\n",
    "global_model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(24,24,3)))\n",
    "global_model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "global_model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "global_model.add(tf.keras.layers.Flatten())\n",
    "global_model.add(tf.keras.layers.Dense(180, activation='relu'))\n",
    "global_model.add(tf.keras.layers.Dense(90, activation='relu'))\n",
    "global_model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "global_model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
